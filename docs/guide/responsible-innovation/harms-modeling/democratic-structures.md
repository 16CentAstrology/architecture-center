---
title: Erosion of social & democratic structures
titleSuffix: Azure Application Architecture Guide
description: The ability for technology to be used to create highly personalized and manipulative experiences can undermine an informed citizenry and trust in societal structures.
author: dcass
ms.date: 04/22/2020
ms.topic: guide
ms.service: architecture-center
ms.category:
  - fcp
ms.subservice: reference-architecture
---

# Type of harm: Erosion of social & democratic structures

_This mask's curvature blocks facial recognition from all angles. The "surveillance exclusion" mask was designed by Jip van Leeuwenstein while he was a student of Utrecht School of the Arts in the Netherlands. (Leeuwenstein)_

## Manipulation

The ability for technology to be used to create highly personalized and manipulative experiences can undermine an informed citizenry and trust in societal structures.

## Misinformation

Disguising fake information as legitimate or credible information.

- How might this technology be used to generate misinformation?
- How could it be used to spread misinformation that appears credible?

*Example: Generation of synthetic speech of a political leader sways an election.*

## Behavioral exploitation

Exploiting personal preferences or patterns of behavior to induce a desired reaction.

- How might this technology be used to observe patterns of behavior?
- How could this technology be used to encourage dysfunctional or maladaptive behaviors?

*Example: Monitoring shopping habits in connected retail environment leads to personalized incentives for impulse shoppers and hoarders.*

## Social detriment

At scale, the way technology impacts people shapes social and economic structures within communities. It can further ingrain elements that include or benefit some, at the exclusion of others.

## Amplification of power inequality

Perpetuating existing class or privilege disparities.

- How might this technology be used in contexts where there are existing social, economic, or class disparities?
- How might people with more power or privilege disproportionately influence the technology?

*Example: Requiring a residential address & phone number to register on a job website could prevent a homeless person from applying for jobs.*

## Stereotype reinforcement

Perpetuating uninformed "conventional wisdom" about historically or statistically underrepresented people.

- How might this technology be used to reinforce or amplify existing social norms or cultural stereotypes?
- How might the data used by this technology cause it to reflect biases or stereotypes?

*Example: Results of an image search for "CEO" could primarily show photos of Caucasian men*

## Loss of individuality

The inability to express a unique perspective.

- How might this technology amplify majority opinions or "group-think"? Conversely, how might unique forms of expression be suppressed.
- In what ways might the data gathered by this technology be used in feedback to people?

*Example: Limited customization options in designing a video game avatar inhibits self-expression of a player's diversity.*

## Loss of representation

Broad categories of generalization obscure, diminish, or erase real identities.

- How could this technology constrain identity options?
- Could it be used to automatically label or categorize people?

*Example: Automatic photo caption assigns incorrect gender identity and age to the subject.*

## Skill degradation and complacency

Overreliance on automation leads to atrophy of manual skills.

- In what ways might this technology reduce the accessibility and ability to use manual controls?

*Example: Overreliance on automation could lead to an inability to gauge the airplane's true orientation because the pilots have been trained to rely on instruments only.*

**Reference Docs**

- [Responsible AI resource center](../index.md)
- [Assessing Harms booklet](downloadable)

**Next Steps**

- [Assessing harms](./index.md)
- [Who may be impacted](./human-understanding.md)
- [Community Jury](../community-jury/index.md)